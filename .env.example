# Claude Context Environment Variables Example
# 
# Copy this file to ~/.context/.env and modify the values as needed
#
# Usage: cp env.example ~/.context/.env

# =============================================================================
# Embedding Provider Configuration
# =============================================================================

# Embedding provider: OpenAI, VoyageAI, Gemini, Ollama, HuggingFace, OpenRouter, VertexAI, Bedrock
EMBEDDING_PROVIDER=OpenAI

# Embedding model (provider-specific)
EMBEDDING_MODEL=text-embedding-3-small

# Embedding batch size for processing (default: 100)
# You can customize it according to the throughput of your embedding model. Generally, larger batch size means less indexing time.
EMBEDDING_BATCH_SIZE=100

# =============================================================================
# OpenAI Configuration
# =============================================================================

# OpenAI API key
OPENAI_API_KEY=your-openai-api-key-here

# OpenAI base URL (optional, for custom endpoints)
# OPENAI_BASE_URL=https://api.openai.com/v1

# =============================================================================
# VoyageAI Configuration
# =============================================================================

# VoyageAI API key
# VOYAGEAI_API_KEY=your-voyageai-api-key-here

# =============================================================================
# Gemini Configuration
# =============================================================================

# Google Gemini API key
# GEMINI_API_KEY=your-gemini-api-key-here

# =============================================================================
# Ollama Configuration
# =============================================================================

# Ollama model name
# OLLAMA_MODEL=

# Ollama host (default: http://localhost:11434)
# OLLAMA_HOST=http://localhost:11434

# =============================================================================
# HuggingFace Configuration
# =============================================================================

# HuggingFace API key (required for HuggingFace provider)
# HUGGINGFACE_API_KEY=your-huggingface-api-key-here

# HuggingFace model name (use provider-specific environment variable)
# HUGGINGFACE_MODEL=sentence-transformers/all-MiniLM-L6-v2

# HuggingFace Inference API URL (optional, for custom endpoints)
# HUGGINGFACE_BASE_URL=https://api-inference.huggingface.co

# =============================================================================
# OpenRouter Configuration
# =============================================================================

# OpenRouter API key (required for OpenRouter provider)
# OPENROUTER_API_KEY=your-openrouter-api-key-here

# OpenRouter model name (use provider-specific environment variable)
# OPENROUTER_MODEL=openai/text-embedding-3-small

# OpenRouter API URL (optional, for custom endpoints)
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# =============================================================================
# Google Vertex AI Configuration
# =============================================================================

# Vertex AI project ID (required for VertexAI provider)
# VERTEXAI_PROJECT_ID=your-gcp-project-id

# Vertex AI location/region (required for VertexAI provider)
# VERTEXAI_LOCATION=us-central1

# Vertex AI model name (use provider-specific environment variable)
# VERTEXAI_MODEL=textembedding-gecko@003

# Path to service account key file (optional, uses default credentials if not provided)
# VERTEXAI_KEY_FILENAME=/path/to/service-account-key.json

# =============================================================================
# AWS Bedrock Configuration
# =============================================================================

# AWS region (required for Bedrock provider)
# BEDROCK_REGION=us-east-1
# Or use standard AWS environment variables (fallback):
# AWS_DEFAULT_REGION=us-east-1
# AWS_REGION=us-east-1

# Bedrock model name (use provider-specific environment variable)
# BEDROCK_MODEL=amazon.titan-embed-text-v2:0

# AWS credentials (optional, uses default AWS credential chain if not provided)
# Option 1: Use Bedrock-specific variables
# BEDROCK_ACCESS_KEY_ID=your-access-key-id
# BEDROCK_SECRET_ACCESS_KEY=your-secret-access-key
# BEDROCK_SESSION_TOKEN=your-session-token
# BEDROCK_PROFILE=default

# Option 2: Use standard AWS environment variables (recommended)
# AWS_ACCESS_KEY_ID=your-access-key-id
# AWS_SECRET_ACCESS_KEY=your-secret-access-key
# AWS_SESSION_TOKEN=your-session-token
# AWS_PROFILE=default

# Note: The system will automatically use standard AWS credential providers:
# 1. Environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)
# 2. AWS_PROFILE environment variable
# 3. Web identity token from AWS_WEB_IDENTITY_TOKEN_FILE
# 4. Shared credentials file (~/.aws/credentials)
# 5. Shared config file (~/.aws/config)
# 6. ECS container credentials
# 7. EC2 instance metadata credentials
# 8. SSO credentials

# =============================================================================
# Vector Database Configuration
# =============================================================================

# Vector database type: milvus, qdrant (default: milvus)
# VECTOR_DATABASE=milvus

# =============================================================================
# Milvus/Zilliz Configuration
# =============================================================================

# Milvus server address. It's optional when you get Zilliz Personal API Key.
MILVUS_ADDRESS=your-zilliz-cloud-public-endpoint

# Milvus authentication token. You can refer to this guide to get Zilliz Personal API Key as your Milvus token.
# https://github.com/zilliztech/claude-context/blob/master/assets/signup_and_get_apikey.png
MILVUS_TOKEN=your-zilliz-cloud-api-key

# =============================================================================
# Qdrant Configuration
# =============================================================================

# To use Qdrant Cloud instead of local Qdrant:
# QDRANT_URL=https://your-cluster.qdrant.io
# QDRANT_API_KEY=your-qdrant-api-key-here

# To use local Qdrant instance:
# QDRANT_HOST=localhost
# QDRANT_PORT=6333
# QDRANT_HTTPS=false


# =============================================================================
# Code Splitter Configuration
# =============================================================================

# Code splitter type: ast, langchain
SPLITTER_TYPE=ast

# =============================================================================
# Custom File Processing Configuration
# =============================================================================

# Additional file extensions to include beyond defaults (comma-separated)
# Example: .vue,.svelte,.astro,.twig,.blade.php
# CUSTOM_EXTENSIONS=.vue,.svelte,.astro

# Additional ignore patterns to exclude files/directories (comma-separated)
# Example: temp/**,*.backup,private/**,uploads/**
# CUSTOM_IGNORE_PATTERNS=temp/**,*.backup,private/**

# Whether to use hybrid search mode. If true, it will use both dense vector and BM25; if false, it will use only dense vector search.
# HYBRID_MODE=true
